{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14562741,"sourceType":"datasetVersion","datasetId":9301907},{"sourceId":14572282,"sourceType":"datasetVersion","datasetId":9308431}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"15461b38","cell_type":"markdown","source":"## Baseline using Yolov8n\n","metadata":{"id":"15461b38"}},{"id":"2GzyBb5mlrtA","cell_type":"code","source":"!pip install ultralytics","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GzyBb5mlrtA","outputId":"1ccd3ab5-4ae9-457e-d704-d575f0f8ca82","trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:43:35.671588Z","iopub.execute_input":"2026-01-21T15:43:35.672125Z","iopub.status.idle":"2026-01-21T15:43:41.168169Z","shell.execute_reply.started":"2026-01-21T15:43:35.672095Z","shell.execute_reply":"2026-01-21T15:43:41.167466Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.4.6-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\nDownloading ultralytics-8.4.6-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.4.6 ultralytics-thop-2.0.18\n","output_type":"stream"}],"execution_count":1},{"id":"c2XQLwz9lyNQ","cell_type":"code","source":"!pip install -U ultralytics sahi","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"c2XQLwz9lyNQ","outputId":"4f5ec015-5026-4ac4-a5ec-dda9015f8c39","trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:43:42.908070Z","iopub.execute_input":"2026-01-21T15:43:42.908375Z","iopub.status.idle":"2026-01-21T15:43:51.436401Z","shell.execute_reply.started":"2026-01-21T15:43:42.908336Z","shell.execute_reply":"2026-01-21T15:43:51.435541Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.4.6)\nCollecting sahi\n  Downloading sahi-0.11.36-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nRequirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\nRequirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sahi) (8.3.1)\nCollecting fire (from sahi)\n  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting opencv-python>=4.6.0 (from ultralytics)\n  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nCollecting pybboxes==0.1.6 (from sahi)\n  Downloading pybboxes-0.1.6-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from sahi) (2.1.2)\nCollecting terminaltables (from sahi)\n  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.12/dist-packages (from sahi) (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->sahi) (3.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\nDownloading sahi-0.11.36-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\nDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\nInstalling collected packages: terminaltables, pybboxes, opencv-python, fire, sahi\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.12.0.88\n    Uninstalling opencv-python-4.12.0.88:\n      Successfully uninstalled opencv-python-4.12.0.88\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fire-0.7.1 opencv-python-4.11.0.86 pybboxes-0.1.6 sahi-0.11.36 terminaltables-3.1.10\n","output_type":"stream"}],"execution_count":2},{"id":"afe0b1e9","cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\n\nmodel = YOLO(\"yolov8n.pt\")\ncap = cv2.VideoCapture(\"/kaggle/input/crowd-5s/crowd_5s.mp4\")\nret, frame = cap.read()\nif ret:\n    results = model(frame)\n    annotated = results[0].plot()  # ← стандартная отрисовка YOLO\n    cv2.imwrite(\"test_frame.jpg\", annotated)\ncap.release()","metadata":{"id":"afe0b1e9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"173f48cd-0634-4516-b5a7-7e9831f811e1","trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:45:18.210149Z","iopub.execute_input":"2026-01-21T15:45:18.210560Z","iopub.status.idle":"2026-01-21T15:45:25.239060Z","shell.execute_reply.started":"2026-01-21T15:45:18.210525Z","shell.execute_reply":"2026-01-21T15:45:25.238376Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 76.5MB/s 0.1s\n\n0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 65.0ms\nSpeed: 4.9ms preprocess, 65.0ms inference, 34.2ms postprocess per image at shape (1, 3, 384, 640)\n","output_type":"stream"}],"execution_count":3},{"id":"2ad16742","cell_type":"markdown","source":"видно что есть лишние объекты и слишком жирная рамка","metadata":{"id":"2ad16742"}},{"id":"d3b77d71","cell_type":"code","source":"import cv2\n\ncap = cv2.VideoCapture(\"../crowd.mp4\")\n\nif not cap.isOpened():\n    raise IOError(\"Cannot open video file\")\n\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\nframe_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\nprint(f\"Resolution: {width}x{height}\")\nprint(f\"FPS: {fps}\")\nprint(f\"Total frames: {frame_count}\")\n\ncap.release()","metadata":{"id":"d3b77d71","outputId":"c3756283-5825-4f61-d497-38a2f53529c5","trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:45:25.250214Z","iopub.status.idle":"2026-01-21T15:45:25.250604Z","shell.execute_reply.started":"2026-01-21T15:45:25.250425Z","shell.execute_reply":"2026-01-21T15:45:25.250445Z"}},"outputs":[],"execution_count":null},{"id":"3089cac0","cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\n\nmodel = YOLO(\"yolov8n.pt\")\n\ncap = cv2.VideoCapture(\"./crowd_5s.mp4\")\nret, frame = cap.read()\n\nif not ret:\n    raise ValueError(\"Failed to read frame from video!\")\n\nresults = model(frame, imgsz=1280)\nboxes = results[0].boxes\n\nannotated_frame = frame.copy()\n\nfor box in boxes:\n    cls_id = int(box.cls.item())\n    conf = float(box.conf.item())\n    xyxy = box.xyxy[0].cpu().numpy()\n\n    if cls_id == 0 and conf > 0.1:\n        x1, y1, x2, y2 = map(int, xyxy)\n        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n        label = f\"person {conf:.2f}\"\n        cv2.putText(\n            annotated_frame,\n            label,\n            (x1, y1 - 10),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            fontScale=0.5,\n            color=(0, 255, 0),\n            thickness=1,\n            lineType=cv2.LINE_AA\n        )\n\ncv2.imwrite(\"annotated_frame1.jpg\", annotated_frame)\ncap.release()\n\nprint(\"✅ Frame processed and saved as 'annotated_frame.jpg'\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3089cac0","outputId":"4858a0cd-82e2-48bc-b5c9-51a73f6a13ed","trusted":true},"outputs":[],"execution_count":null},{"id":"e49334e4-9379-47f9-9cf5-2382cd665abe","cell_type":"markdown","source":"## Сравнение быстродействия трех подходов - Yolov8n , Yolov8s + SAHI , RT-DETR от Baidu ","metadata":{}},{"id":"d23b215e-93c5-437c-af84-09f6a76ec9bb","cell_type":"code","source":"import cv2\nimport time\nfrom ultralytics import YOLO, RTDETR\nfrom sahi import AutoDetectionModel\nfrom sahi.predict import get_sliced_prediction\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:45:36.523460Z","iopub.execute_input":"2026-01-21T15:45:36.523802Z","iopub.status.idle":"2026-01-21T15:45:36.703877Z","shell.execute_reply.started":"2026-01-21T15:45:36.523772Z","shell.execute_reply":"2026-01-21T15:45:36.703013Z"}},"outputs":[],"execution_count":6},{"id":"ccdea431-2b96-45ce-a19e-58aca64749b2","cell_type":"code","source":"def draw_boxes(frame, boxes, label=\"person\"):\n    \"\"\"Draw bounding boxes and labels on frame.\"\"\"\n    annotated = frame.copy()\n    for xyxy, conf in boxes:\n        x1, y1, x2, y2 = map(int, xyxy)\n        cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)\n        text = f\"{label} {conf:.2f}\"\n        cv2.putText(\n            annotated, text, (x1, y1 - 10),\n            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA\n        )\n    return annotated\n\ndef extract_person_detections(results):\n    \"\"\"Extract person detections from YOLO/RT-DETR results.\"\"\"\n    boxes = []\n    for box in results[0].boxes:\n        cls_id = int(box.cls.item())\n        conf = float(box.conf.item())\n        if cls_id == 0 and conf > 0.3:\n            xyxy = box.xyxy[0].cpu().numpy()\n            boxes.append((xyxy, conf))\n    return boxes\n\ndef extract_person_detections_sahi(result):\n    \"\"\"Extract person detections from SAHI result.\"\"\"\n    boxes = []\n    for obj in result.object_prediction_list:\n        if obj.category.name == \"person\":\n            conf = obj.score.value\n            if conf > 0.3:\n                x1, y1, x2, y2 = obj.bbox.to_voc_bbox()\n                boxes.append(([x1, y1, x2, y2], conf))\n    return boxes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:45:38.187922Z","iopub.execute_input":"2026-01-21T15:45:38.188375Z","iopub.status.idle":"2026-01-21T15:45:38.197094Z","shell.execute_reply.started":"2026-01-21T15:45:38.188333Z","shell.execute_reply":"2026-01-21T15:45:38.195997Z"}},"outputs":[],"execution_count":7},{"id":"d5c172ca-c095-4aa9-b46f-30ce581323a9","cell_type":"code","source":"VIDEO_PATH = \"/kaggle/input/crowd-5s/crowd_5s.mp4\"\nN_FRAMES = 30\n\ncap = cv2.VideoCapture(VIDEO_PATH)\nframes = []\nfor _ in range(N_FRAMES):\n    ret, frame = cap.read()\n    if not ret:\n        break\n    frames.append(frame)\ncap.release()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:45:40.755834Z","iopub.execute_input":"2026-01-21T15:45:40.756532Z","iopub.status.idle":"2026-01-21T15:45:41.070751Z","shell.execute_reply.started":"2026-01-21T15:45:40.756499Z","shell.execute_reply":"2026-01-21T15:45:41.070127Z"}},"outputs":[],"execution_count":8},{"id":"6ae86af6-71cb-462b-a6f2-5e4b1bec9265","cell_type":"markdown","source":"### Yolov8n","metadata":{}},{"id":"d22d52f2-2006-4684-ad75-9bd71bd84297","cell_type":"code","source":"model_yolo = YOLO(\"yolov8n.pt\")\nmodel_yolo.to('cuda')\ntimes_yolo = []\nlast_detections_yolo = []\n\nfor i, frame in enumerate(frames):\n    start = time.time()\n    results = model_yolo(frame, imgsz=1280, verbose=False)\n    boxes = extract_person_detections(results)\n    elapsed = time.time() - start\n    times_yolo.append(elapsed)\n    if i == len(frames) - 1:\n        last_detections_yolo = boxes\n        img_yolo = draw_boxes(frame, boxes)\n        cv2.imwrite(\"yolo8.jpg\", img_yolo)\n\navg_time_yolo = sum(times_yolo) / len(times_yolo)\nprint(f\"YOLOv8n — avg time: {avg_time_yolo:.3f}s, persons in last frame: {len(last_detections_yolo)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:46:00.207265Z","iopub.execute_input":"2026-01-21T15:46:00.207816Z","iopub.status.idle":"2026-01-21T15:46:01.036098Z","shell.execute_reply.started":"2026-01-21T15:46:00.207784Z","shell.execute_reply":"2026-01-21T15:46:01.035276Z"}},"outputs":[{"name":"stdout","text":"YOLOv8n — avg time: 0.020s, persons in last frame: 16\n","output_type":"stream"}],"execution_count":10},{"id":"79618ffb-436c-4487-b22c-2f1341edbf7a","cell_type":"markdown","source":"### Yolo26","metadata":{}},{"id":"25614c3d-bd87-480a-bf5f-d835ed38405a","cell_type":"code","source":"model_yolo = YOLO(\"yolo26l.pt\")\nmodel_yolo.to('cuda')\ntimes_yolo = []\nlast_detections_yolo = []\n\nfor i, frame in enumerate(frames):\n    start = time.time()\n    results = model_yolo(frame, imgsz=1280, verbose=False)\n    boxes = extract_person_detections(results)\n    elapsed = time.time() - start\n    times_yolo.append(elapsed)\n    if i == len(frames) - 1:\n        last_detections_yolo = boxes\n        img_yolo = draw_boxes(frame, boxes)\n        cv2.imwrite(\"yolov26.jpg\", img_yolo)\n\navg_time_yolo = sum(times_yolo) / len(times_yolo)\nprint(f\"YOLO26l — avg time: {avg_time_yolo:.3f}s, persons in last frame: {len(last_detections_yolo)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:38:53.795002Z","iopub.execute_input":"2026-01-21T15:38:53.795317Z","iopub.status.idle":"2026-01-21T15:39:02.892473Z","shell.execute_reply.started":"2026-01-21T15:38:53.795288Z","shell.execute_reply":"2026-01-21T15:39:02.891656Z"}},"outputs":[{"name":"stdout","text":"YOLO26l — avg time: 0.286s, persons in last frame: 20\n","output_type":"stream"}],"execution_count":27},{"id":"adb97242-5401-490a-957c-92c1c75e9cfb","cell_type":"markdown","source":"### Yolov8 + SAHI","metadata":{}},{"id":"741310e6-5f3e-48fc-93d3-635504df59cc","cell_type":"code","source":"sahi_model = AutoDetectionModel.from_pretrained(\n    model_type=\"yolov8\",\n    model_path=\"yolov8s.pt\",\n    confidence_threshold=0.3,\n    device=\"cuda\"\n)\n\ntimes_sahi = []\nlast_detections_sahi = []\n\nfor i, frame in enumerate(frames):\n    start = time.time()\n    result = get_sliced_prediction(\n        image=frame,\n        detection_model=sahi_model,\n        slice_height=512,\n        slice_width=512,\n        overlap_height_ratio=0.2,\n        overlap_width_ratio=0.2\n    )\n    boxes = extract_person_detections_sahi(result)\n    elapsed = time.time() - start\n    times_sahi.append(elapsed)\n    if i == len(frames) - 1:\n        last_detections_sahi = boxes\n        img_sahi = draw_boxes(frame, boxes)\n        cv2.imwrite(\"img_sahi.jpg\", img_sahi)\n\n\navg_time_sahi = sum(times_sahi) / len(times_sahi)\nprint(f\"SAHI (YOLOv8m) — avg time: {avg_time_sahi:.3f}s, persons in last frame: {len(last_detections_sahi)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:25:58.784647Z","iopub.execute_input":"2026-01-21T15:25:58.785177Z","iopub.status.idle":"2026-01-21T15:26:28.650788Z","shell.execute_reply.started":"2026-01-21T15:25:58.785147Z","shell.execute_reply":"2026-01-21T15:26:28.650036Z"}},"outputs":[{"name":"stdout","text":"Performing prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nSAHI (YOLOv8m) — avg time: 0.990s, persons in last frame: 30\n","output_type":"stream"}],"execution_count":22},{"id":"0aea1b11-3530-4bf7-ac6e-3eebc84a1e2c","cell_type":"markdown","source":"### RTDETR","metadata":{}},{"id":"5fb964fe-0312-4a76-b7ad-8df4bc0d6bdd","cell_type":"code","source":"model_rtdetr = RTDETR(\"rtdetr-l.pt\")\nmodel_rtdetr.to(\"cuda\")\n\ntimes_rtdetr = []\nlast_detections_rtdetr = []\n\nfor i, frame in enumerate(frames):\n    start = time.time()\n    results = model_rtdetr(frame, imgsz=1280, verbose=False)\n    boxes = extract_person_detections(results)  # same format as YOLO\n    elapsed = time.time() - start\n    times_rtdetr.append(elapsed)\n    if i == len(frames) - 1:\n        last_detections_rtdetr = boxes\n        img_rtdetr = draw_boxes(frame, boxes)\n        cv2.imwrite(\"img_rtdetr.jpg\", img_rtdetr)\n\navg_time_rtdetr = sum(times_rtdetr) / len(times_rtdetr)\nprint(f\"RT-DETR — avg time: {avg_time_rtdetr:.3f}s, persons in last frame: {len(last_detections_rtdetr)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:28:22.392626Z","iopub.execute_input":"2026-01-21T15:28:22.393420Z","iopub.status.idle":"2026-01-21T15:28:35.315509Z","shell.execute_reply.started":"2026-01-21T15:28:22.393372Z","shell.execute_reply":"2026-01-21T15:28:35.314882Z"}},"outputs":[{"name":"stdout","text":"RT-DETR — avg time: 0.410s, persons in last frame: 26\n","output_type":"stream"}],"execution_count":23},{"id":"1f861713-bfed-4354-8dfb-1ffe62952c6c","cell_type":"markdown","source":"### RTDETR + SAHI","metadata":{}},{"id":"5c55b182-641e-4292-9e85-005f4bf1be11","cell_type":"code","source":"sahi_model = AutoDetectionModel.from_pretrained(\n    model_type=\"ultralytics\",\n    model_path=\"rtdetr-l.pt\",\n    device=\"cuda\"\n)\n\ntimes_sahi = []\nlast_detections_sahi = []\n\nfor i, frame in enumerate(frames):\n    start = time.time()\n    result = get_sliced_prediction(\n        image=frame,\n        detection_model=sahi_model,\n        slice_height=512,\n        slice_width=512,\n        overlap_height_ratio=0.2,\n        overlap_width_ratio=0.2\n    )\n    boxes = extract_person_detections_sahi(result)\n    elapsed = time.time() - start\n    times_sahi.append(elapsed)\n    if i == len(frames) - 1:\n        last_detections_sahi = boxes\n        img_sahi = draw_boxes(frame, boxes)\n        cv2.imwrite(\"img_sahi_rtder.jpg\", img_sahi)\n\n\navg_time_sahi = sum(times_sahi) / len(times_sahi)\nprint(f\"SAHI (YOLOv8m) — avg time: {avg_time_sahi:.3f}s, persons in last frame: {len(last_detections_sahi)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:28:53.162245Z","iopub.execute_input":"2026-01-21T15:28:53.163036Z","iopub.status.idle":"2026-01-21T15:30:06.776675Z","shell.execute_reply.started":"2026-01-21T15:28:53.163002Z","shell.execute_reply":"2026-01-21T15:30:06.775889Z"}},"outputs":[{"name":"stdout","text":"Performing prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nPerforming prediction on 15 slices.\nSAHI (YOLOv8m) — avg time: 2.436s, persons in last frame: 37\n","output_type":"stream"}],"execution_count":24},{"id":"d85dc9a2","cell_type":"markdown","source":"# Видеопоток\n","metadata":{"id":"d85dc9a2"}},{"id":"48d94faf-4bc8-4515-8bed-5cbddccec1e8","cell_type":"markdown","source":"Для лучшего сочетания сохраним видео.","metadata":{}},{"id":"f657a485","cell_type":"code","source":"import cv2\nimport os\nfrom ultralytics import RTDETR\nfrom sahi import AutoDetectionModel\nfrom sahi.predict import get_sliced_prediction\n\n\nsahi_model = AutoDetectionModel.from_pretrained(\n    model_type=\"rtdetr\",\n    model_path=\"rtdetr-l.pt\",\n    confidence_threshold=0.35,\n    device=\"cuda\"\n)\n\ninput_video_path = \"/kaggle/input/full-crowd/crowd.mp4\"\noutput_video_path = \"output_sahi_rtdetr.avi\"\n\nif not os.path.exists(input_video_path):\n    raise FileNotFoundError(f\"Input video not found: {input_video_path}\")\n\ncap = cv2.VideoCapture(input_video_path)\nif not cap.isOpened():\n    raise IOError(f\"Cannot open video: {input_video_path}\")\n\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*\"XVID\")\nout = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\nframe_count = 0\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    result = get_sliced_prediction(\n        image=frame,\n        detection_model=sahi_model,\n        slice_height=512,\n        slice_width=512,\n        overlap_height_ratio=0.2,\n        overlap_width_ratio=0.2,\n        verbose=0\n    )\n\n    boxes = extract_person_detections_sahi(result)\n    annotated_frame = draw_boxes(frame, boxes)\n    out.write(annotated_frame)\n    frame_count += 1\n\ncap.release()\nout.release()\n","metadata":{"id":"f657a485","outputId":"4685c0db-1268-4e4b-a06b-cea1dc3d282e","trusted":true,"execution":{"iopub.status.busy":"2026-01-21T16:13:47.302340Z","iopub.execute_input":"2026-01-21T16:13:47.303151Z","iopub.status.idle":"2026-01-21T16:25:20.796563Z","shell.execute_reply.started":"2026-01-21T16:13:47.303116Z","shell.execute_reply":"2026-01-21T16:25:20.795790Z"}},"outputs":[{"name":"stdout","text":"\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/rtdetr-l.pt to 'rtdetr-l.pt': 100% ━━━━━━━━━━━━ 63.4MB 179.2MB/s 0.4s0.3s<0.1s\n","output_type":"stream"}],"execution_count":11}]}