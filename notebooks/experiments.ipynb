{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15461b38",
   "metadata": {},
   "source": [
    "## Baseline using Yolov8n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe0b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 78.8ms\n",
      "Speed: 2.3ms preprocess, 78.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "cap = cv2.VideoCapture(\"../crowd.mp4\")\n",
    "ret, frame = cap.read()\n",
    "if ret:\n",
    "    results = model(frame)\n",
    "    annotated = results[0].plot()  # â† ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð°Ñ Ð¾Ñ‚Ñ€Ð¸ÑÐ¾Ð²ÐºÐ° YOLO\n",
    "    cv2.imwrite(\"test_frame.jpg\", annotated)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad16742",
   "metadata": {},
   "source": [
    "Ð²Ð¸Ð´Ð½Ð¾ Ñ‡Ñ‚Ð¾ ÐµÑÑ‚ÑŒ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹ Ð¸ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð¶Ð¸Ñ€Ð½Ð°Ñ Ñ€Ð°Ð¼ÐºÐ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3b77d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution: 1920x1080\n",
      "FPS: 29.97002997002997\n",
      "Total frames: 705\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"../crowd.mp4\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open video file\")\n",
    "\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Resolution: {width}x{height}\")\n",
    "print(f\"FPS: {fps}\")\n",
    "print(f\"Total frames: {frame_count}\")\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3089cac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 21 persons, 1 bus, 3 umbrellas, 3 handbags, 1 tv, 207.4ms\n",
      "Speed: 9.3ms preprocess, 207.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "âœ… Frame processed and saved as 'annotated_frame.jpg'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(\"../crowd.mp4\")\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    raise ValueError(\"Failed to read frame from video!\")\n",
    "\n",
    "results = model(frame, imgsz=1280)\n",
    "boxes = results[0].boxes\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "\n",
    "for box in boxes:\n",
    "    cls_id = int(box.cls.item())\n",
    "    conf = float(box.conf.item())\n",
    "    xyxy = box.xyxy[0].cpu().numpy()\n",
    "\n",
    "    if cls_id == 0 and conf > 0.1:\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "        label = f\"person {conf:.2f}\"\n",
    "        cv2.putText(\n",
    "            annotated_frame,\n",
    "            label,\n",
    "            (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=0.5,\n",
    "            color=(0, 255, 0),\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "cv2.imwrite(\"annotated_frame.jpg\", annotated_frame)\n",
    "cap.release()\n",
    "\n",
    "print(\"âœ… Frame processed and saved as 'annotated_frame.jpg'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85dc9a2",
   "metadata": {},
   "source": [
    "# Ð²Ð¸Ð´ÐµÐ¾Ð¿Ð¾Ñ‚Ð¾Ðº\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fabd49d",
   "metadata": {},
   "source": [
    "Ð£Ñ€ÐµÐ¶ÐµÐ¼ Ð²Ð¸Ð´ÐµÐ¾ Ð´Ð»Ñ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÑ‚Ð¾Ð²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f657a485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ torchvision==0.24 is incompatible with torch==2.7.\n",
      "Run 'pip install torchvision==0.22' to fix torchvision or 'pip install -U torch torchvision' to update both.\n",
      "For a full compatibility table see https://github.com/pytorch/vision#installation\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 201.9ms\n",
      "Speed: 10.2ms preprocess, 201.9ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 1 umbrella, 1 handbag, 79.8ms\n",
      "Speed: 2.7ms preprocess, 79.8ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 1 handbag, 64.4ms\n",
      "Speed: 2.2ms preprocess, 64.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 3 umbrellas, 1 handbag, 126.3ms\n",
      "Speed: 5.4ms preprocess, 126.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 98.7ms\n",
      "Speed: 6.2ms preprocess, 98.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 87.7ms\n",
      "Speed: 1.9ms preprocess, 87.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 82.5ms\n",
      "Speed: 1.8ms preprocess, 82.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 80.4ms\n",
      "Speed: 2.1ms preprocess, 80.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 79.9ms\n",
      "Speed: 1.9ms preprocess, 79.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 98.8ms\n",
      "Speed: 1.8ms preprocess, 98.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 90.3ms\n",
      "Speed: 2.4ms preprocess, 90.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 93.1ms\n",
      "Speed: 2.1ms preprocess, 93.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 44.5ms\n",
      "Speed: 16.4ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 65.6ms\n",
      "Speed: 3.7ms preprocess, 65.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 47.2ms\n",
      "Speed: 2.7ms preprocess, 47.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 44.0ms\n",
      "Speed: 2.4ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 83.5ms\n",
      "Speed: 3.9ms preprocess, 83.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 42.1ms\n",
      "Speed: 3.1ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 60.4ms\n",
      "Speed: 1.6ms preprocess, 60.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 51.9ms\n",
      "Speed: 4.6ms preprocess, 51.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 50.0ms\n",
      "Speed: 4.8ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 40.7ms\n",
      "Speed: 2.7ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 39.1ms\n",
      "Speed: 3.6ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 49.4ms\n",
      "Speed: 4.0ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 56.1ms\n",
      "Speed: 6.8ms preprocess, 56.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 51.2ms\n",
      "Speed: 5.5ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 handbag, 1 dining table, 64.6ms\n",
      "Speed: 3.4ms preprocess, 64.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 57.0ms\n",
      "Speed: 1.8ms preprocess, 57.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 60.7ms\n",
      "Speed: 1.9ms preprocess, 60.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 84.1ms\n",
      "Speed: 2.4ms preprocess, 84.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 84.3ms\n",
      "Speed: 2.1ms preprocess, 84.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 1 dining table, 76.0ms\n",
      "Speed: 2.5ms preprocess, 76.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 76.0ms\n",
      "Speed: 2.7ms preprocess, 76.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 stop sign, 2 umbrellas, 1 dining table, 75.2ms\n",
      "Speed: 1.7ms preprocess, 75.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 1 dining table, 81.7ms\n",
      "Speed: 2.0ms preprocess, 81.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 1 dining table, 48.3ms\n",
      "Speed: 3.4ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 1 dining table, 43.9ms\n",
      "Speed: 2.7ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 44.4ms\n",
      "Speed: 2.9ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 1 dining table, 41.5ms\n",
      "Speed: 3.0ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 dining table, 43.7ms\n",
      "Speed: 2.1ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 dining table, 41.6ms\n",
      "Speed: 1.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 stop sign, 2 umbrellas, 56.3ms\n",
      "Speed: 3.3ms preprocess, 56.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 stop sign, 2 umbrellas, 58.9ms\n",
      "Speed: 3.9ms preprocess, 58.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 stop sign, 2 umbrellas, 49.0ms\n",
      "Speed: 4.1ms preprocess, 49.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 stop sign, 2 umbrellas, 57.0ms\n",
      "Speed: 2.1ms preprocess, 57.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 stop sign, 2 umbrellas, 48.8ms\n",
      "Speed: 7.3ms preprocess, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 44.8ms\n",
      "Speed: 20.5ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 stop sign, 2 umbrellas, 51.9ms\n",
      "Speed: 5.5ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 42.4ms\n",
      "Speed: 1.8ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 stop sign, 2 umbrellas, 42.2ms\n",
      "Speed: 2.1ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 stop sign, 2 umbrellas, 40.5ms\n",
      "Speed: 2.1ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 stop sign, 2 umbrellas, 34.2ms\n",
      "Speed: 2.1ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 stop sign, 2 umbrellas, 50.7ms\n",
      "Speed: 1.8ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 46.9ms\n",
      "Speed: 1.8ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 65.0ms\n",
      "Speed: 2.6ms preprocess, 65.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 stop sign, 2 umbrellas, 41.5ms\n",
      "Speed: 2.0ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 stop sign, 2 umbrellas, 49.4ms\n",
      "Speed: 2.0ms preprocess, 49.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 3 umbrellas, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 57.9ms\n",
      "Speed: 1.9ms preprocess, 57.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 63.6ms\n",
      "Speed: 1.8ms preprocess, 63.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 54.9ms\n",
      "Speed: 1.9ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 41.5ms\n",
      "Speed: 3.1ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 dining table, 40.3ms\n",
      "Speed: 5.8ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 dining table, 49.0ms\n",
      "Speed: 4.4ms preprocess, 49.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 umbrella, 1 dining table, 40.6ms\n",
      "Speed: 1.9ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 umbrella, 1 dining table, 39.5ms\n",
      "Speed: 1.7ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 49.5ms\n",
      "Speed: 1.8ms preprocess, 49.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 umbrellas, 48.3ms\n",
      "Speed: 2.6ms preprocess, 48.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 umbrellas, 37.6ms\n",
      "Speed: 3.4ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 umbrellas, 43.6ms\n",
      "Speed: 1.7ms preprocess, 43.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 umbrellas, 57.3ms\n",
      "Speed: 4.5ms preprocess, 57.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 52.9ms\n",
      "Speed: 1.6ms preprocess, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 39.9ms\n",
      "Speed: 3.3ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 1 dining table, 49.0ms\n",
      "Speed: 2.9ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 dining table, 42.5ms\n",
      "Speed: 2.9ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 113.7ms\n",
      "Speed: 3.2ms preprocess, 113.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 dining table, 47.8ms\n",
      "Speed: 2.4ms preprocess, 47.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 dining table, 47.5ms\n",
      "Speed: 1.6ms preprocess, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 51.3ms\n",
      "Speed: 1.8ms preprocess, 51.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 dining table, 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 dining table, 42.2ms\n",
      "Speed: 1.7ms preprocess, 42.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 dining table, 44.0ms\n",
      "Speed: 2.2ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 dining table, 40.8ms\n",
      "Speed: 2.5ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 umbrellas, 1 dining table, 39.2ms\n",
      "Speed: 2.8ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 umbrellas, 1 dining table, 54.0ms\n",
      "Speed: 5.6ms preprocess, 54.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 umbrellas, 1 dining table, 43.9ms\n",
      "Speed: 1.9ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 dog, 1 umbrella, 1 dining table, 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 dog, 1 umbrella, 1 dining table, 39.3ms\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 umbrella, 1 dining table, 55.2ms\n",
      "Speed: 1.8ms preprocess, 55.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 umbrella, 1 dining table, 55.7ms\n",
      "Speed: 2.1ms preprocess, 55.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 cat, 1 dog, 1 umbrella, 1 dining table, 83.5ms\n",
      "Speed: 2.2ms preprocess, 83.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 umbrella, 1 dining table, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 umbrella, 1 dining table, 78.7ms\n",
      "Speed: 1.8ms preprocess, 78.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 umbrella, 1 dining table, 79.9ms\n",
      "Speed: 2.7ms preprocess, 79.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 umbrella, 1 chair, 1 dining table, 74.4ms\n",
      "Speed: 2.1ms preprocess, 74.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 umbrella, 1 chair, 1 dining table, 71.2ms\n",
      "Speed: 2.6ms preprocess, 71.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 umbrella, 1 chair, 1 dining table, 44.4ms\n",
      "Speed: 1.7ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 umbrella, 1 chair, 82.0ms\n",
      "Speed: 8.1ms preprocess, 82.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 umbrella, 1 chair, 36.8ms\n",
      "Speed: 2.2ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 1 umbrella, 1 chair, 38.0ms\n",
      "Speed: 1.6ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 chair, 39.5ms\n",
      "Speed: 4.7ms preprocess, 39.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 2 chairs, 41.2ms\n",
      "Speed: 2.4ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 umbrellas, 2 chairs, 40.3ms\n",
      "Speed: 3.1ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 chair, 41.3ms\n",
      "Speed: 4.4ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 40.7ms\n",
      "Speed: 1.7ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 57.9ms\n",
      "Speed: 1.9ms preprocess, 57.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 umbrella, 40.2ms\n",
      "Speed: 3.2ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 umbrella, 38.3ms\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 umbrella, 55.1ms\n",
      "Speed: 2.9ms preprocess, 55.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 dining table, 39.1ms\n",
      "Speed: 2.8ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 44.1ms\n",
      "Speed: 2.6ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 42.8ms\n",
      "Speed: 2.5ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 dining table, 41.8ms\n",
      "Speed: 4.5ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 44.7ms\n",
      "Speed: 5.5ms preprocess, 44.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 52.2ms\n",
      "Speed: 3.5ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 42.8ms\n",
      "Speed: 1.7ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 handbag, 1 dining table, 133.9ms\n",
      "Speed: 2.7ms preprocess, 133.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 1 handbag, 1 dining table, 44.2ms\n",
      "Speed: 1.9ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 dining table, 39.2ms\n",
      "Speed: 3.4ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 umbrellas, 1 chair, 1 dining table, 51.6ms\n",
      "Speed: 1.6ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 48.1ms\n",
      "Speed: 1.9ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 40.8ms\n",
      "Speed: 3.4ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 38.4ms\n",
      "Speed: 1.8ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 umbrellas, 1 handbag, 39.1ms\n",
      "Speed: 5.8ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 1 handbag, 54.7ms\n",
      "Speed: 3.6ms preprocess, 54.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 1 handbag, 48.2ms\n",
      "Speed: 4.2ms preprocess, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 handbag, 45.7ms\n",
      "Speed: 3.4ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 2 handbags, 69.6ms\n",
      "Speed: 1.7ms preprocess, 69.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 2 umbrellas, 1 handbag, 66.9ms\n",
      "Speed: 3.7ms preprocess, 66.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 2 umbrellas, 1 handbag, 109.4ms\n",
      "Speed: 4.8ms preprocess, 109.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 1 backpack, 2 umbrellas, 1 dining table, 76.5ms\n",
      "Speed: 4.3ms preprocess, 76.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 2 umbrellas, 1 dining table, 49.5ms\n",
      "Speed: 2.1ms preprocess, 49.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 handbag, 1 dining table, 46.7ms\n",
      "Speed: 1.7ms preprocess, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 55.8ms\n",
      "Speed: 3.0ms preprocess, 55.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 1 handbag, 41.2ms\n",
      "Speed: 1.7ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 1 backpack, 2 umbrellas, 1 handbag, 36.7ms\n",
      "Speed: 1.9ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 40.6ms\n",
      "Speed: 2.4ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 93.6ms\n",
      "Speed: 8.8ms preprocess, 93.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 2 umbrellas, 1 handbag, 38.3ms\n",
      "Speed: 4.1ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 46.5ms\n",
      "Speed: 1.6ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 38.6ms\n",
      "Speed: 1.8ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 2 umbrellas, 1 handbag, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 42.6ms\n",
      "Speed: 1.8ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 1 backpack, 2 umbrellas, 1 handbag, 52.2ms\n",
      "Speed: 13.6ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 backpack, 2 umbrellas, 1 handbag, 100.7ms\n",
      "Speed: 1.8ms preprocess, 100.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 umbrellas, 86.9ms\n",
      "Speed: 2.2ms preprocess, 86.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 1 umbrella, 76.9ms\n",
      "Speed: 2.2ms preprocess, 76.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 umbrellas, 77.3ms\n",
      "Speed: 1.6ms preprocess, 77.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 backpack, 2 umbrellas, 76.7ms\n",
      "Speed: 2.0ms preprocess, 76.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "âœ… Processing complete. Output saved as '../detect.avi'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Open input video\n",
    "input_video_path = \"./crowd_5s.mp4\"  # Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ñ„Ð°Ð¹Ð» Ð»ÐµÐ¶Ð¸Ñ‚ Ð² Ñ€Ð°Ð±Ð¾Ñ‡ÐµÐ¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸\n",
    "capture = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "if not capture.isOpened():\n",
    "    raise IOError(f\"Cannot open video file: {input_video_path}\")\n",
    "\n",
    "# Get video properties\n",
    "fps = int(capture.get(cv2.CAP_PROP_FPS))\n",
    "width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ AVI Ð´Ð»Ñ Ð½Ð°Ð´Ñ‘Ð¶Ð½Ð¾ÑÑ‚Ð¸\n",
    "output_video_path = \"../detect.avi\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Process each frame\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run inference with higher resolution for better accuracy on 1080p video\n",
    "    results = model(frame)\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls.item())\n",
    "        conf = float(box.conf.item())\n",
    "        xyxy = box.xyxy[0].cpu().numpy()\n",
    "\n",
    "        # Only detect 'person' (class ID 0 in COCO)\n",
    "        if cls_id == 0 and conf > 0.3:  # reasonable confidence threshold\n",
    "            x1, y1, x2, y2 = map(int, xyxy)\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "            label = f\"person {conf:.2f}\"\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                label,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=0.5,\n",
    "                color=(0, 255, 0),\n",
    "                thickness=1,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "    writer.write(annotated_frame)\n",
    "\n",
    "# Release resources\n",
    "capture.release()\n",
    "writer.release()\n",
    "\n",
    "print(f\"âœ… Processing complete. Output saved as '{output_video_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe921967",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-version\u001b[39m\u001b[38;5;124m\"\u001b[39m], stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mDEVNULL, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mDEVNULL, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ”§ Converting to H.264 MP4 for compatibility...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun([\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-y\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_avi_path,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-c:v\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibx264\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-crf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m23\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-pix_fmt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myuv420p\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-preset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfast\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     output_mp4_path\n\u001b[1;32m      8\u001b[0m ], stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mDEVNULL, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mDEVNULL)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subprocess' is not defined"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "subprocess.run([\"ffmpeg\", \"-version\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "\n",
    "print(\"ðŸ”§ Converting to H.264 MP4 for compatibility...\")\n",
    "result = subprocess.run([\n",
    "    \"ffmpeg\", \"-y\", \"-i\", output_video_path,\n",
    "    \"-c:v\", \"libx264\", \"-crf\", \"23\", \"-pix_fmt\", \"yuv420p\", \"-preset\", \"fast\",\n",
    "    output_video_path\n",
    "], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11f8a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"crowd.mp4\"))  # Ð”Ð¾Ð»Ð¶Ð½Ð¾ Ð±Ñ‹Ñ‚ÑŒ True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778024e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/demon/ML/recognize_people/Detecting-people/notebooks'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
